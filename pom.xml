<project>
  <groupId>com.databricks</groupId>
  <artifactId>spark-test-failures</artifactId>
  <modelVersion>4.0.0</modelVersion>
  <name>Spark Test Failures</name>
  <packaging>jar</packaging>
  <version>1.0</version>
  <properties>
    <spark.version>1.5.1</spark.version>
  </properties>
  <repositories>
    <repository>
      <id>Spark Staging Repo</id>
      <url>https://repository.apache.org/content/repositories/orgapachespark-1075/</url>
    </repository>
  </repositories>
  <dependencies>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_2.10</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_2.10</artifactId>
      <version>${spark.version}</version>
    </dependency>
    <dependency>
      <groupId>com.google.gdata</groupId>
      <artifactId>core</artifactId>
      <version>1.47.1</version>
    </dependency>
    <dependency>
      <groupId>com.google.apis</groupId>
      <artifactId>google-api-services-oauth2</artifactId>
      <version>v2-rev87-1.19.1</version>
    </dependency>
    <dependency>
      <groupId>com.google.apis</groupId>
      <artifactId>google-api-services-drive</artifactId>
      <version>v2-rev161-1.19.1</version>
    </dependency>
    <dependency>
      <groupId>com.google.http-client</groupId>
      <artifactId>google-http-client-jackson</artifactId>
      <version>1.19.0</version>
    </dependency>
  </dependencies>
  <build>
    <plugins>
      <plugin>
      <groupId>org.scala-tools</groupId>
      <artifactId>maven-scala-plugin</artifactId>
      <version>2.15.2</version>
      <executions>
        <execution>
        <goals>
          <goal>compile</goal>
        </goals>
        </execution>
      </executions>
      </plugin>
<!--
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <version>2.1</version>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
            <configuration>
              <minimizeJar>false</minimizeJar>
              <createDependencyReducedPom>false</createDependencyReducedPom>
              <filters>
                <filter>
                  <artifact>*:*</artifact>
                  <excludes>
                    <exclude>META-INF/*.SF</exclude>
                    <exclude>META-INF/*.DSA</exclude>
                    <exclude>META-INF/*.RSA</exclude>
                  </excludes>
                </filter>
              </filters>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                  <resource>reference.conf</resource>
                </transformer>
              </transformers>
            </configuration>
          </execution>
        </executions>
      </plugin>
-->

      <plugin>
        <groupId>org.codehaus.mojo</groupId>
        <artifactId>exec-maven-plugin</artifactId>
        <version>1.4.0</version>
        <executions>
          <execution>
            <goals>
              <goal>exec</goal>
            </goals>
          </execution>
        </executions>
        <configuration>
          <executable>java</executable>
          <!-- optional -->
          <workingDirectory>target</workingDirectory>
          <arguments>
            <argument>-classpath</argument>
            <classpath/>

            <!--
            <argument>-Dspark.test.jenkins.url.base=https://amplab.cs.berkeley.edu/jenkins/job</argument>
            <argument>-Dspark.test.jenkinsProjects=Spark-1.5-Maven-with-YARN</argument>
            <argument>-Dspark.test.packages=org.apache.spark</argument>

            <argument>-Dspark.test.jenkinsProjects=SparkPullRequestBuilder</argument>
            <argument>-Dspark.test.jenkinsProjects=Spark-Master-SBT</argument>
            <argument>-Dspark.test.empty.column=(N/A)</argument>
            <argument>-Dspark.test.outputFileDelimiter=,</argument>
            // 48h
            <argument>-Dspark.test.fetcher.maxTestAge.seconds=172800</argument>

-->

            <argument>-Dspark.test.jenkins.url.base=https://builds.apache.org/job</argument>
            <argument>-Dspark.test.jenkinsProjects=Hadoop-Common-trunk</argument>
            <argument>-Dspark.test.packages=org.apache.hadoop</argument>
            <argument>-Dspark.test.outputFileName=jenkins.txt</argument>
            <argument>-Dspark.test.fetcher.maxTestAge.seconds=432000</argument>
            <argument>com.databricks.fetcher.JenkinsFetcher</argument>
          </arguments>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
